{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manulera/ShareYourCloning_backend/blob/master/RSE_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q224Wx3btex",
        "outputId": "e7a7a4e3-da7f-46cb-ba05-3fd7582ccf99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/BjornFJohansson/pydna@4fd760d075f77cceeb27969e017e04b42f6d0aa3\n",
            "  Cloning https://github.com/BjornFJohansson/pydna (to revision 4fd760d075f77cceeb27969e017e04b42f6d0aa3) to /tmp/pip-req-build-ko0c02zf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/BjornFJohansson/pydna /tmp/pip-req-build-ko0c02zf\n",
            "  Running command git rev-parse -q --verify 'sha^4fd760d075f77cceeb27969e017e04b42f6d0aa3'\n",
            "  Running command git fetch -q https://github.com/BjornFJohansson/pydna 4fd760d075f77cceeb27969e017e04b42f6d0aa3\n",
            "  Resolved https://github.com/BjornFJohansson/pydna to commit 4fd760d075f77cceeb27969e017e04b42f6d0aa3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from pydna==6.0.0a26.post23+4fd760d) (1.4.4)\n",
            "Collecting biopython>=1.80 (from pydna==6.0.0a26.post23+4fd760d)\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.8.8 in /usr/local/lib/python3.10/dist-packages (from pydna==6.0.0a26.post23+4fd760d) (3.2.1)\n",
            "Collecting numpy>1.26 (from pydna==6.0.0a26.post23+4fd760d)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prettytable>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from pydna==6.0.0a26.post23+4fd760d) (3.10.0)\n",
            "Collecting pydivsufsort>=0.0.11 (from pydna==6.0.0a26.post23+4fd760d)\n",
            "  Downloading pydivsufsort-0.0.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyfiglet==0.8.post1 (from pydna==6.0.0a26.post23+4fd760d)\n",
            "  Downloading pyfiglet-0.8.post1-py2.py3-none-any.whl (865 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.8/865.8 kB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seguid<0.0.4,>=0.0.3 (from pydna==6.0.0a26.post23+4fd760d)\n",
            "  Downloading seguid-0.0.3-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable>=3.5.0->pydna==6.0.0a26.post23+4fd760d) (0.2.13)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from pydivsufsort>=0.0.11->pydna==6.0.0a26.post23+4fd760d) (0.42.0)\n",
            "Building wheels for collected packages: pydna\n",
            "  Building wheel for pydna (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydna: filename=pydna-6.0.0a26.post23+4fd760d-py3-none-any.whl size=122143 sha256=d7d5f469c81dc6da1b1fd343ecef788d54f430c9fa276e7ed5d73f52b126ad22\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/08/bf/488909658e8c365ccb4c04aa99e299b5d2834a3128ab3b19b4\n",
            "Successfully built pydna\n",
            "Installing collected packages: pyfiglet, seguid, numpy, pydivsufsort, biopython, pydna\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "Successfully installed biopython-1.83 numpy-1.26.4 pydivsufsort-0.0.14 pydna-6.0.0a26.post23+4fd760d pyfiglet-0.8.post1 seguid-0.0.3\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install pip dependencies\n",
        "!pip install git+https://github.com/BjornFJohansson/pydna@4fd760d075f77cceeb27969e017e04b42f6d0aa3\n",
        "!pip install regex\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7eoi6QvcpwS",
        "outputId": "a71c6c3b-501f-481e-86ef-dd2388d2a22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-01 10:05:28--  https://raw.githubusercontent.com/manulera/ShareYourCloning_backend/master/dna_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8250 (8.1K) [text/plain]\n",
            "Saving to: ‘dna_functions.py’\n",
            "\n",
            "\rdna_functions.py      0%[                    ]       0  --.-KB/s               \rdna_functions.py    100%[===================>]   8.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-01 10:05:28 (80.3 MB/s) - ‘dna_functions.py’ saved [8250/8250]\n",
            "\n",
            "--2024-03-01 10:05:28--  https://raw.githubusercontent.com/manulera/ShareYourCloning_backend/master/pydantic_models.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10174 (9.9K) [text/plain]\n",
            "Saving to: ‘pydantic_models.py’\n",
            "\n",
            "pydantic_models.py  100%[===================>]   9.94K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-03-01 10:05:28 (15.9 MB/s) - ‘pydantic_models.py’ saved [10174/10174]\n",
            "\n",
            "--2024-03-01 10:05:28--  https://raw.githubusercontent.com/manulera/ShareYourCloning_backend/master/assembly2.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39860 (39K) [text/plain]\n",
            "Saving to: ‘assembly2.py’\n",
            "\n",
            "assembly2.py        100%[===================>]  38.93K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-03-01 10:05:29 (12.9 MB/s) - ‘assembly2.py’ saved [39860/39860]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get files to import functions\n",
        "import os\n",
        "if not os.path.isfile('dna_functions.py'):\n",
        "  !wget 'https://raw.githubusercontent.com/manulera/ShareYourCloning_backend/master/dna_functions.py'\n",
        "if not os.path.isfile('pydantic_models.py'):\n",
        "  !wget 'https://raw.githubusercontent.com/manulera/ShareYourCloning_backend/master/pydantic_models.py'\n",
        "if not os.path.isfile('assembly2.py'):\n",
        "  !wget 'https://raw.githubusercontent.com/manulera/ShareYourCloning_backend/master/assembly2.py'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2t7fFyRB6Yj"
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67H6RCJpNbBC"
      },
      "source": [
        "Simplistically, we can think of DNA sequences as text strings. Molecular cloning would be the experimental manipulations that allow us to copy-paste fragments of different sequences to generate a new sequence. The problem is that there is not a recognised standard or data model to represent these manipulations, and therefore no way to document the provenance of sequences.\n",
        "\n",
        "[ShareYourCloning](https://shareyourcloning.netlify.app/) is a project that aims to develop:\n",
        "* A data model to represent the \"source\" of a sequence. A source can be either:\n",
        "  * A minimal description of an experimental manipulation that also links the child sequence to its parents\n",
        "  * Metadata indicating the provenance of externally imported or naturally occurring DNA sequences (e.g. an identifier in a plasmid repository, or the genome coordinates of a gene of interest).\n",
        "* A web application for researchers to plan molecular cloning and export it in that data model format.\n",
        "\n",
        "You can see a [video](https://www.youtube.com/watch?v=HRQb6s8m8_s&t=2s&ab_channel=Genestorian) of an older version of the app, or visit the [hosted version](https://shareyourcloning.netlify.app/) to see how it looks. It has a [FastAPI python backend](https://github.com/manulera/ShareYourCloning_backend) and a [React Frontend](https://github.com/manulera/ShareYourCloning_frontend) (repos linked)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svLKmzBAfSti"
      },
      "source": [
        "## This notebook\n",
        "\n",
        "This notebook is a followup to [this issue](https://github.com/manulera/ShareYourCloning_backend/issues/83) where I describe the kind of questions that I have. In this network I give some practical examples of what I am trying to do, and how it could map to a data model / schema.\n",
        "\n",
        "The thing to keep in mind while going through this notebook is that I want to use [LinkML](https://linkml.io/linkml/index.html), a framework to define data models because:\n",
        "  * You describe your schema using yaml, but it can turn your schema into other things (json schema, SQL...) and it has a framework for migration of the schema.\n",
        "  * It can produce pydantic models that are used by FastAPI as API inputs and return values (FastAPI parses the request payload json into pydantic objects and serializes pydantic objects into json for the response).\n",
        "  * The other side of the coin is that if I did not use LinkML-generated pydantic models and I wrote my own, I could add methods to them that are convenient for parsing some inputs, and some fields would have non-natural data types (for instance, restriction enzyme class from Biopython instead of a list of strings containing enzyme names).\n",
        "\n",
        "I have included `> Note` in comments where I think input would be useful, and I have added some questions at the end.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-2k5nRRB1Iv"
      },
      "source": [
        "# Representing sources of sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI9gRD61B3cv"
      },
      "source": [
        "For now, sources of sequences are represented as pydantic models, they are all children of the class \"Source\" that has the following\n",
        "fields:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lnUdytcfjUz",
        "outputId": "26374eec-3c02-49d1-ba7a-d1f051e226bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': FieldInfo(annotation=Union[int, NoneType], required=False, description='Unique identifier of the source'),\n",
              " 'kind': FieldInfo(annotation=str, required=False, default='source', description='The kind entity (always equal to \"source\"). Should probably be removed.'),\n",
              " 'input': FieldInfo(annotation=list[int], required=False, default=[], description=\"Identifiers of the sequences that are an input to this source.                              If the source represents external import of a sequence, it's empty.\"),\n",
              " 'output': FieldInfo(annotation=Union[int, NoneType], required=False, description='Identifier of the sequence that is an output of this source.'),\n",
              " 'type': FieldInfo(annotation=Union[SourceType, NoneType], required=True, description='The type source (PCR, restriction, etc.)'),\n",
              " 'info': FieldInfo(annotation=dict, required=False, default={}, description='Additional information about the source (not used much yet, and probably should be removed)')}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydantic_models import Source\n",
        "\n",
        "Source.model_fields\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNTgHymEDg9Z"
      },
      "source": [
        "# Representing the sequences themselves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqzaGB12Dsmg"
      },
      "source": [
        "I don't pay much attention to this, because most of the info of a sequence is stored as genbank (in a string), but there is a pydantic model to represent sequences in order to:\n",
        "* Assign them a unique identifier, so they can be linked to sources as inputs or outputs.\n",
        "* Document whether they have sequence overhangs.\n",
        "  > What are Overhangs? Normally, the DNA sequences that we use in the lab are double-stranded DNA, but sometimes they can have single-stranded DNA at one of their ends, and this is call an overhang. This can happen when cutting with a [restriction enzyme](https://images.ctfassets.net/d49zkrle08v9/7dmzFrgzvfdgg0IK0jZ6v6/64d89fb0722f498561bf1c3be9072bf4/Restriction_enzyme_cuts.png)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT4D0asXDlus",
        "outputId": "e3a9f8e8-bb11-4deb-b1cd-df311972378f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': FieldInfo(annotation=Union[int, NoneType], required=False, description='Unique identifier of the sequence'),\n",
            " 'kind': FieldInfo(annotation=str, required=False, default='entity', description='The kind entity (always equal to \"entity\"). Should probably be removed.'),\n",
            " 'sequence': FieldInfo(annotation=Union[GenbankSequence, NoneType], required=True, description='The sequence in genbank format + some extra info that is not captured by the genbank format')}\n",
            "\n",
            "{'file_content': FieldInfo(annotation=str, required=False, default=''),\n",
            " 'file_extension': FieldInfo(annotation=str, required=False, default='gb'),\n",
            " 'overhang_crick_3prime': FieldInfo(annotation=int, required=False, default=0, description=\"Taken from pydna's `dseq::ovhg`        An integer describing the length of the        crick strand overhang in the 5' of the molecule, or 3' of the crick strand\"),\n",
            " 'overhang_watson_3prime': FieldInfo(annotation=int, required=False, default=0, description='The equivalent of `overhang_crick_3prime`        but for the watson strand'),\n",
            " 'type': FieldInfo(annotation=str, required=False, default='file')}\n"
          ]
        }
      ],
      "source": [
        "from pydantic_models import SequenceEntity, GenbankSequence\n",
        "import pprint\n",
        "\n",
        "pp = pprint.PrettyPrinter(depth=4)\n",
        "pp.pprint(SequenceEntity.model_fields)\n",
        "print()\n",
        "pp.pprint(GenbankSequence.model_fields)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCpYhz4ZjwT5"
      },
      "source": [
        "# Example 1 - Restriction cut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKkHkT3VWp5o"
      },
      "source": [
        "## 0 What's a restriction cut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbdlxozDWikJ"
      },
      "source": [
        "\n",
        "Let's look at a first example: how we simulate and document the cut by a restriction enzyme.\n",
        "\n",
        "Restriction enzymes cut the DNA at particular sequences. For instance, the enzyme `EcoRI` cuts on sequence `G^AATT_C`, meaning that if the sequence\n",
        "`GAATTC` is present, it will cut after the `G` on the top strand, and after the\n",
        "second `T` on the bottom strand.\n",
        "\n",
        "![](https://images.ctfassets.net/d49zkrle08v9/7dmzFrgzvfdgg0IK0jZ6v6/64d89fb0722f498561bf1c3be9072bf4/Restriction_enzyme_cuts.png)\n",
        "\n",
        "\n",
        "These are the extra fields that the source representing enzyme cuts contains, they will be explained in detail below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEXVa6m-lqIB",
        "outputId": "4451cee8-f68d-430f-ace2-f820dab5d956"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'left_edge': FieldInfo(annotation=Union[tuple[int, int], NoneType], required=False, description='The left edge of the cut, in the format (cut_watson, ovhg)'),\n",
              " 'right_edge': FieldInfo(annotation=Union[tuple[int, int], NoneType], required=False, description='The right edge of the cut, in the format (cut_watson, ovhg)'),\n",
              " 'restriction_enzymes': FieldInfo(annotation=List[Union[str, NoneType]], required=True, description='Enzymes associated with the left and right sides of the cut. It can contain None to represent the edge the sequence in linear sequences.', metadata=[Len(min_length=1, max_length=None)])}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydantic_models import RestrictionEnzymeDigestionSource\n",
        "\n",
        "restriction_fields = RestrictionEnzymeDigestionSource.model_fields.copy()\n",
        "\n",
        "for key in Source.model_fields:\n",
        "  restriction_fields.pop(key)\n",
        "\n",
        "restriction_fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F4lULy_lgDU"
      },
      "source": [
        "The web API receives as input:\n",
        "* The sequence to be cut\n",
        "* A `RestrictionEnzymeDigestionSource` object where only the `restriction_enzymes` field is populated with a list of enzymes as strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t-YakNosKax"
      },
      "source": [
        "## 1 API inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NZk0FAvkIix",
        "outputId": "4dd49488-0bfe-4e62-e66b-84bf6855bad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dseq(-18)\n",
              "ACGAATTCTAGAATTCAA\n",
              "TGCTTAAGATCTTAAGTT"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydna.dseqrecord import Dseqrecord\n",
        "from Bio.Restriction.Restriction import RestrictionBatch\n",
        "\n",
        "\n",
        "# The input sequence actually comes as a pydantic object and then\n",
        "# would be transformed into a Dseqrecord (Biopython object that represents\n",
        "# a double-stranded sequence), for now let's skip that.\n",
        "input_sequence = Dseqrecord('ACGAATTCTAGAATTCAA')\n",
        "\n",
        "# Note that the source that is submitted to the server still does not\n",
        "# have an id (it will be assigned at the frontend once the user picks the desired\n",
        "# fragment)\n",
        "input_source = RestrictionEnzymeDigestionSource(\n",
        "            input=[1],\n",
        "            restriction_enzymes=['EcoRI'],\n",
        "        )\n",
        "\n",
        "# We convert the list of enzyme strings into a set of enzyme objects\n",
        "# using the Biopython library.\n",
        "enzymes = RestrictionBatch(first=[e for e in input_source.restriction_enzymes])\n",
        "# > Note: This could be done directly when the object is received by the API,\n",
        "# the field `restriction_enzymes` could be of type `RestrictionBatch`, and one\n",
        "# can write a parser that converts the json input into that. That would be the\n",
        "# ideal scenario, but not sure that is compatible with LinkML.\n",
        "\n",
        "\n",
        "# See how this object represents a double stranded sequence\n",
        "input_sequence.seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evRbpZxtsOeq"
      },
      "source": [
        "## 2 Simulating the cloning + keeping track of what we do\n",
        "\n",
        "We can simulate this using the cloning library, as shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJme7f3mkodl",
        "outputId": "4c90dd7a-2f65-4d12-86a6-67faff3ee148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parent\n",
            "Dseq(-18)\n",
            "ACGAATTCTAGAATTCAA\n",
            "TGCTTAAGATCTTAAGTT\n",
            "\n",
            "child1\n",
            "Dseq(-7)\n",
            "ACG\n",
            "TGCTTAA\n",
            "\n",
            "child2\n",
            "Dseq(-12)\n",
            "AATTCTAG\n",
            "    GATCTTAA\n",
            "\n",
            "child3\n",
            "Dseq(-7)\n",
            "AATTCAA\n",
            "    GTT\n"
          ]
        }
      ],
      "source": [
        "print('parent', input_sequence.seq.__repr__(), sep='\\n')\n",
        "print()\n",
        "child1, child2, child3 = input_sequence.cut(enzymes)\n",
        "print('child1', child1.seq.__repr__(), sep='\\n')\n",
        "print()\n",
        "print('child2', child2.seq.__repr__(), sep='\\n')\n",
        "print()\n",
        "print('child3', child3.seq.__repr__(), sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKFWjaRht2lH"
      },
      "source": [
        "In the actual API call, we do this in several steps, to keep track also of where the cut happens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zOyiXUawE6O"
      },
      "source": [
        "\n",
        "### Find cutsites\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL7frl39wLtG"
      },
      "source": [
        "\n",
        "First, we get the cutsites present in the sequence for the given enzymes. A cutsite is represented as `((cut_watson, ovhg), enz)`:\n",
        "\n",
        "- `cut_watson` is a positive integer contained in `[0,len(seq))`, where `seq` is the sequence that will be cut. It represents the position of the cut on the watson strand.\n",
        "- `ovhg` is the overhang left after the cut. For the example `EcoRI`, the value is -4 (4 bases missing from top strand in the left fragment after the cut).\n",
        "- `enz` is the enzyme object. It's not necessary to perform the cut, but can be used to keep track of which enzyme was used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjp8st5tqdd",
        "outputId": "b17b043b-18fe-44db-9924-27f95b3404bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((3, -4), EcoRI), ((11, -4), EcoRI)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cutsites = input_sequence.seq.get_cutsites(*enzymes)\n",
        "cutsites\n",
        "# > Note: these cutsites are defined as tuples, but this is probably not very\n",
        "# data model-friendly, would it make sense to turn them into a class?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIs1LFk_wdag"
      },
      "source": [
        "### Pairing cutsites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOebzudIvPGi"
      },
      "source": [
        "A fragment produced by restriction is represented by a tuple of length 2 that may contain cutsites or `None`:\n",
        "\n",
        "- Two cutsites: represents the extraction of a fragment between those two cutsites, in that orientation.\n",
        "- `None`, cutsite: represents the extraction of a fragment between the left edge of linear sequence and the cutsite.\n",
        "- cutsite, `None`: represents the extraction of a fragment between the cutsite and the right edge of a linear sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afQlRvsmxEcl",
        "outputId": "d6941a83-a60d-44de-bdf9-03af96669464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, ((3, -4), EcoRI))\n",
            "(((3, -4), EcoRI), ((11, -4), EcoRI))\n",
            "(((11, -4), EcoRI), None)\n"
          ]
        }
      ],
      "source": [
        "cutsite_pairs = input_sequence.seq.get_cutsite_pairs(cutsites)\n",
        "\n",
        "for s in cutsite_pairs:\n",
        "  print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi0h6jeCyAtk"
      },
      "source": [
        "This information is sufficient to instantiate a `RestrictionEnzymeDigestionSource` describing the provenance of each fragment, so we create one for each:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jznv7gd_yTg5",
        "outputId": "a70fe801-096b-4b98-d600-18db272b094d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id=None kind='source' input=[1] output=None type=<SourceType.restriction: 'restriction'> info={} left_edge=None right_edge=(3, -4) restriction_enzymes=[None, 'EcoRI']\n",
            "id=None kind='source' input=[1] output=None type=<SourceType.restriction: 'restriction'> info={} left_edge=(3, -4) right_edge=(11, -4) restriction_enzymes=['EcoRI', 'EcoRI']\n",
            "id=None kind='source' input=[1] output=None type=<SourceType.restriction: 'restriction'> info={} left_edge=(11, -4) right_edge=None restriction_enzymes=['EcoRI', None]\n"
          ]
        }
      ],
      "source": [
        "sources = list()\n",
        "for (left_cut, right_cut) in cutsite_pairs:\n",
        "  sources.append(\n",
        "      RestrictionEnzymeDigestionSource.from_cutsites(\n",
        "          left=left_cut,\n",
        "          right=right_cut,\n",
        "          input=input_source.input, # This we already knew\n",
        "          id=input_source.id\n",
        "      )\n",
        "  )\n",
        "\n",
        "# Let's print them\n",
        "for s in sources:\n",
        "  print(s)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHPGAOBgxruT"
      },
      "source": [
        "### Executing the cut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voHUtP8wx4r6"
      },
      "source": [
        "Now we want to generate all possible fragments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfBfvO-LxrDZ",
        "outputId": "523803b3-c3a5-4e06-f298-2b4d9b2c199e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dseq(-7)\n",
            "ACG\n",
            "TGCTTAA\n",
            "\n",
            "Dseq(-12)\n",
            "AATTCTAG\n",
            "    GATCTTAA\n",
            "\n",
            "Dseq(-7)\n",
            "AATTCAA\n",
            "    GTT\n",
            "\n"
          ]
        }
      ],
      "source": [
        "fragments = list()\n",
        "for (left_cut, right_cut) in cutsite_pairs:\n",
        "  fragments.append(input_sequence.apply_cut(left_cut,right_cut))\n",
        "\n",
        "# Verify that they are the same as before:\n",
        "for f in fragments:\n",
        "  print(f.seq.__repr__())\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SqcB-Nd0uPn"
      },
      "source": [
        "## 3 Returning values to user\n",
        "\n",
        "Now we simply return a response containing a list of possible sources and sequences, and the user picks one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tq0i-CEa_Y-z"
      },
      "outputs": [],
      "source": [
        "from dna_functions import format_sequence_genbank\n",
        "# format_sequence_genbank converts the sequence object into json\n",
        "formatted_fragments = [format_sequence_genbank(f) for f in fragments]\n",
        "\n",
        "# This would be the return value of the API.\n",
        "return_value = {'sequences': formatted_fragments, 'sources': sources}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EQzgejU_9F4"
      },
      "source": [
        "# Example 2 - A Gibson assembly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He3NLscoLHmv"
      },
      "source": [
        "## 0 What is a Gibson Assembly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sksw862AHzs"
      },
      "source": [
        "In essence, a Gibson assembly can join sequences based on \"common substrings\". Imagine we have three DNA sequences `ataCCC` `CCCttaTTT` `TTTgcg`. One possible Gibson assembly would be:\n",
        "\n",
        "```\n",
        "ataCCC\n",
        "   |||\n",
        "   CCCttaTTT\n",
        "         |||\n",
        "         TTTgcg\n",
        "\n",
        "Produces:\n",
        "ataCCCttaTTTgcg\n",
        "```\n",
        "\n",
        "> Info: Gibson assemblies join sequences only if these common substrings are at the end, but other types of assemblies can produce joins like this:\n",
        "> ```\n",
        "> CCCttaTTTaa\n",
        ">       |||\n",
        ">     ccTTTgcg\n",
        ">  \n",
        "> Output: CCCttaTTTgcg (aa and cc are lost)\n",
        "> ```\n",
        "\n",
        "Consider that these sequences are double-stranded DNA, so they could be joined in either orientation, let's take the middle sequence as an example:\n",
        "\n",
        "```\n",
        "Forward orientation            Reverse orientation\n",
        "\n",
        "CCCttaTTT                      AAAtaaGGG\n",
        "|||||||||                      |||||||||\n",
        "GGGaatAAA                      TTTattCCC\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MV8ZGetJoko"
      },
      "source": [
        "The `GibsonAssemblySource` represents a Gibson assembly, and contains two extra fields as shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4seoz_KJnsr",
        "outputId": "ad864297-0d9f-4c7f-9831-d0b38b8910ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'assembly': FieldInfo(annotation=Union[Annotated[List[tuple[int, int, str, str]], Len], NoneType], required=False, description='The assembly plan as a list of tuples (part_1_id, part_2_id, loc1, loc2)'),\n",
              " 'circular': FieldInfo(annotation=Union[bool, NoneType], required=False, description='Whether the assembly is circular or not')}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydantic_models import GibsonAssemblySource\n",
        "\n",
        "gibson_fields = GibsonAssemblySource.model_fields.copy()\n",
        "\n",
        "for key in Source.model_fields:\n",
        "  gibson_fields.pop(key)\n",
        "\n",
        "gibson_fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3LVlnV9KIGM"
      },
      "source": [
        "\n",
        "The list of tuples `assembly` contains the information of how to join subfragments of the parent sequences to produce the child sequence.\n",
        "As mentioned in the previous [GitHub issue](https://github.com/manulera/ShareYourCloning_backend/issues/83), if the three example sequences above had ids 10, 11 and 12. The field assembly would contain the following:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"assembly\": [\n",
        "        [1, 2, \"3..6\", \"0..3\"],\n",
        "        [2, 3, \"6..9\", \"0..3\"]\n",
        "    ],\n",
        "}\n",
        "```\n",
        "\n",
        "The `assembly` field is an array of 4-length arrays, each of them representing the join between two fragments:\n",
        "\n",
        "- The first and second integers represent the index (one-based) of the joined fragments in the input list. The sign of the integer represents the orientation of each fragment, positive for forward orientation, negative for reverse orientation.\n",
        "- The strings represent the location of the overlap in the first and second fragment. This is standard sequence location syntax.\n",
        "- The assembly can be a loop in some cases if it starts and finishes with the same fragment, the `circular` fields indicates that.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NibaCB2QW_6q"
      },
      "source": [
        "## 1 API Inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSfmD20VXEl3",
        "outputId": "5c07100b-b33c-474f-f975-1b3d3ed1543c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SequenceEntity(id=10, kind='entity', sequence=GenbankSequence(type='file', file_extension='gb', file_content='LOCUS       name                       6 bp    DNA     linear   UNK 01-JAN-1980\\nDEFINITION  description.\\nACCESSION   id\\nVERSION     id\\nKEYWORDS    .\\nSOURCE      .\\n  ORGANISM  .\\n            .\\nFEATURES             Location/Qualifiers\\nORIGIN\\n        1 ataccc\\n//', overhang_crick_3prime=0, overhang_watson_3prime=0))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The API receives a list of sequences as pydantic objects, below we construct\n",
        "# those objects using the function\n",
        "\n",
        "sequences= [\n",
        "  Dseqrecord('ataCCC'),\n",
        "  Dseqrecord('CCCttaTTT'),\n",
        "  Dseqrecord('TTTgcg')\n",
        "]\n",
        "\n",
        "input_sequences = [format_sequence_genbank(s) for s in sequences]\n",
        "ids = [10, 11, 12]\n",
        "\n",
        "for seq, seq_id in zip(input_sequences, ids):\n",
        "  seq.id = seq_id\n",
        "\n",
        "# This is how the seq pydantic object looks (note that the entire gb file is\n",
        "# contained in the sequence.file_content field)\n",
        "input_sequences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O_Th918HZKTq"
      },
      "outputs": [],
      "source": [
        "# The other input is a GibsonAssemblySource where the only set field is input\n",
        "input_source = GibsonAssemblySource(\n",
        "            input=[10, 11, 12],\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWJ4kNIFat21"
      },
      "source": [
        "Basically, the payload of the request is:\n",
        "```json\n",
        "{\n",
        "  \"source\": input_source,\n",
        "  \"sequences\": input_sequences\n",
        "}\n",
        "```\n",
        "\n",
        "Note that this is not great, because from the start there is no way to guarantee that the ids in `input_sequences` correspond to the ones in `input_source.input`.\n",
        "> One obvious fix for this particular use-case is to not send the source at all in the payload, and just send the sequences. The issue is that the same endpoint can be used to get all possible assemblies (as we are using now, when only the `input` field is set), as well as to execute a particular known assembly (if `assembly` and `circular` fields are set), so that problem would also exist there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlqEjJWtcPlQ",
        "outputId": "54ab6b3a-56e9-42c7-fbed-9ebe4e2776dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Dseqrecord(-6), Dseqrecord(-9), Dseqrecord(-6)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dna_functions import read_dsrecord_from_json\n",
        "\n",
        "# Because of the issue with ids in input not necessarily matching those of the\n",
        "# sequences, this is how I process the inputs:\n",
        "fragments = [next((read_dsrecord_from_json(seq) for seq in input_sequences if seq.id == id), None) for id in input_source.input]\n",
        "if any(f is None for f in fragments):\n",
        "  # Commented out because it needs api library for special error\n",
        "  # raise HTTPException(400, f'Invalid fragment id in input')\n",
        "  pass\n",
        "\n",
        "# Fragments now contains the dseqrecords of the input sequences:\n",
        "fragments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leWtluCxdZ6Q"
      },
      "source": [
        "## 2 Simulating the cloning - keeping track of what we do"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYYgprj1ezWz"
      },
      "source": [
        "We can simulate this using the cloning library, as shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVAHQ7Pwdhlc",
        "outputId": "f5429b12-157c-42bf-bb3f-6408bfd1b341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "possible assemblies length: 1\n",
            "Dseq(-15)\n",
            "ATACCCTTATTTGCG\n",
            "TATGGGAATAAACGC\n"
          ]
        }
      ],
      "source": [
        "from assembly2 import Assembly, gibson_overlap, assembly2str, assemble\n",
        "\n",
        "# this is a parameter that the user sets, describing the minimal homology\n",
        "# required to join fragments, for this dummy example we use 3, in reality\n",
        "# more would be needed\n",
        "minimal_homology = 3\n",
        "\n",
        "# This object contains all assemblies\n",
        "asm = Assembly(fragments, algorithm=gibson_overlap, use_fragment_order=False, use_all_fragments=True, limit=minimal_homology)\n",
        "\n",
        "# We want all possible assemblies\n",
        "possible_assemblies = asm.assemble_linear() + asm.assemble_circular()\n",
        "\n",
        "# Only the one we mentioned above is returned (it's the only possible one)\n",
        "print('possible assemblies length:',len(possible_assemblies))\n",
        "print(possible_assemblies[0].seq.__repr__())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcBRyeVe1QNe"
      },
      "source": [
        "### Why are assemblies represented like that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFi06Dsou4lZ"
      },
      "source": [
        "To understand why the assemblies are represented the way they are, it may make sense to understand how the possible assemblies are calculated.\n",
        "\n",
        "The `Assembly` class contains a directed graph, where nodes represent fragments and edges represent overlaps between fragments:\n",
        "- The node keys are integers, representing the index of the fragment in the input list of fragments. The sign of the node key represents the orientation of the fragment, positive for forward orientation, negative for reverse orientation.\n",
        "- The edges contain the locations of the overlaps in the fragments. For an edge `(u, v, key)`:\n",
        "    - `u` and `v` are the nodes connected by the edge.\n",
        "    - key is a string that represents the location of the overlap. In the format introduced above:\n",
        "    `u[start:end](strand):v[start:end](strand)`.\n",
        "    - Edges have a `locations` attribute, which is a list of two `Location` objects, representing the location of the overlap in the `u` and `v` fragment.\n",
        "    - You can think of an edge as a representation of the join of two fragments.\n",
        "\n",
        "Let's look at how the edges of the previous graph look"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSwVcGSXu3CT",
        "outputId": "b0b9e422-0e19-41ca-cc6a-effe65d2919a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 2, '1[3:6]:2[0:3]')\n",
            "(2, 3, '2[6:9]:3[0:3]')\n",
            "(-2, -1, '-2[6:9]:-1[0:3]')\n",
            "(-3, -2, '-3[3:6]:-2[0:3]')\n"
          ]
        }
      ],
      "source": [
        "print(*asm.G.edges, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M29QmEG7y2TI",
        "outputId": "1497996f-84d9-44aa-e7cd-65fc9cf77663"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "possible assemblies: 1\n",
            "((1, 2, SimpleLocation(ExactPosition(3), ExactPosition(6)), SimpleLocation(ExactPosition(0), ExactPosition(3))), (2, 3, SimpleLocation(ExactPosition(6), ExactPosition(9)), SimpleLocation(ExactPosition(0), ExactPosition(3))))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# we can also get the linear assemblies represented as explained above\n",
        "assemblies = asm.get_linear_assemblies()\n",
        "print('possible assemblies:', len(assemblies))\n",
        "\n",
        "# Note that here, the locations of the assembly are not strings (unlike in the\n",
        "# GibsonAssemblySource), they are Location objects (from Biopython)\n",
        "# > Note: this is a case where adding a custom parser to the pydantic assembly\n",
        "# pydantic objects would reduce the need to convert.\n",
        "print(assemblies[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMwPpaH-zpYt",
        "outputId": "031b5dc4-a6bd-4b29-faa6-0db456b9504c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('1[3:6]:2[0:3]', '2[6:9]:3[0:3]')\n"
          ]
        }
      ],
      "source": [
        "# For a concise representation we use this function:\n",
        "print(assembly2str(assemblies[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnzfTQir2-VG",
        "outputId": "b36b9b19-19ad-4fcc-9116-4ccf16d66622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "((1, -2, SimpleLocation(ExactPosition(3), ExactPosition(6)), SimpleLocation(ExactPosition(0), ExactPosition(3))), (-2, 3, SimpleLocation(ExactPosition(6), ExactPosition(9)), SimpleLocation(ExactPosition(0), ExactPosition(3))))\n"
          ]
        }
      ],
      "source": [
        "# See how it changes when one of the elements is inverted (that's what we get with\n",
        "# reverse_complement)\n",
        "fragments2 = [fragments[0], fragments[1].reverse_complement(), fragments[2]]\n",
        "asm = Assembly(fragments2, algorithm=gibson_overlap, use_fragment_order=False, use_all_fragments=True, limit=minimal_homology)\n",
        "assembly_plan = asm.get_linear_assemblies()[0]\n",
        "print(assembly_plan)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB-07b-i5_QG",
        "outputId": "fe55575b-1753-4c78-ea01-1633529b039a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dseq(-15)\n",
              "ATACCCTTATTTGCG\n",
              "TATGGGAATAAACGC"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# When to want to generate the sequence given by a particular assembly you use\n",
        "# the function assemble:\n",
        "assembled_seq = assemble(fragments=fragments2, assembly=assembly_plan, is_circular=False)\n",
        "\n",
        "assembled_seq.seq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XdCsh-swLS7"
      },
      "source": [
        "Using the indexes in the fragment input list to the `Assembly` class is convenient because we want to apply the following constrains:\n",
        "* Assemblies should contain all fragments in the input only once\n",
        "* Each possible assembly must be returned only once.\n",
        "\n",
        "We can use a graph library to find paths between nodes and easily apply these constrains:\n",
        "* Representing a fragment and its reverse complement as 1,-1 2,-2 etc. makes it easy to apply the constrain that each fragment must be present only once.\n",
        "* The linear assembly from above `('1[3:6]:2[0:3]', '2[6:9]:3[0:3]')` is identical to `('-3[3:6]:-2[0:3]', '-2[6:9]:-1[0:3]')`, it's just the reverse complement (inverted fragments in inverted order). We apply the constrain that the first element always must be always in the forward orientation in linear assemblies.\n",
        "* We also apply this in circular assembly, with the extra constrain that the first element in the assembly is the one with the smallest index. Otherwise, a circular assembly of 3 elements could be represented in three different ways.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox5uijiG1cmp"
      },
      "source": [
        "### Back to the cloning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "h4KnXhB31f09"
      },
      "outputs": [],
      "source": [
        "# To keep track of the cloning information, this is how I do it\n",
        "\n",
        "asm = Assembly(fragments, algorithm=gibson_overlap, use_fragment_order=False, use_all_fragments=True, limit=minimal_homology)\n",
        "\n",
        "# We want all possible assemblies\n",
        "possible_assemblies = asm.get_linear_assemblies() + asm.get_circular_assemblies()\n",
        "\n",
        "# This is a lambda function to shorten the code in the loop, since we use it\n",
        "# twice to instantiate GibsonAssemblySource objects\n",
        "create_source = lambda a, is_circular : GibsonAssemblySource.from_assembly(assembly=a, circular=is_circular, id=input_source.id, input=input_source.input)\n",
        "\n",
        "asm = Assembly(fragments, algorithm=gibson_overlap, use_fragment_order=False, use_all_fragments=True, limit=minimal_homology)\n",
        "out_sources = [create_source(a, True) for a in asm.get_circular_assemblies()]\n",
        "out_sources += [create_source(a, False) for a in asm.get_linear_assemblies()]\n",
        "\n",
        "# Important thing to notice here that out_source is a list of\n",
        "# GibsonAssemblySource (pydantic objects) which means that they contain\n",
        "# locations as strings, but below we need the locations again as objects\n",
        "# to generate the output sequences, so we convert back those strings into\n",
        "# locations again.\n",
        "\n",
        "out_sequences = [format_sequence_genbank(assemble(fragments, s.get_assembly_plan(), s.circular)) for s in out_sources]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwmGBOj47DNK"
      },
      "source": [
        "### 3 Returning values to user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UIsTY_CV7GMk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This would be the return value of the API.\n",
        "return_value = {'sequences': out_sequences, 'sources': out_sources}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj9jUdp4A296"
      },
      "source": [
        "# Questions / Input\n",
        "\n",
        "This works to represent cuts and assemblies, but there must be a better way:\n",
        "* Does it make sense to turn the cut representation as a tuple to an object with fields? Instead of `((cut_watson, ovhg), enzyme)`, turn it into an object with those fields.\n",
        "* At least in the python code, using ids to point from sources to sequences is not great, it would be better instead to point directly to the objects. Not sure what would be the best way to do it in the API calls.\n",
        "  * Would it be better to make the source a property of the sequence object via a sequence object property (`outputOf` or `comesFrom`), instead of pointing to the sequence from the source via the source's `output` property?\n",
        "    > This would not fix the issue with the input field.\n",
        "* The representation of assemblies is convenient for the python code, but what would be a good representation in the data model?\n",
        "  * There are several ways to turn it into objects with fields, but it should still be an ordered list, is that something OK to have?\n",
        "* Any other thought on the data model\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOun8ht2tEz+k7DSrAU4vLI",
      "collapsed_sections": [
        "z-2k5nRRB1Iv",
        "dNTgHymEDg9Z",
        "eCpYhz4ZjwT5",
        "qKkHkT3VWp5o",
        "9t-YakNosKax",
        "IIs1LFk_wdag",
        "KHPGAOBgxruT",
        "9EQzgejU_9F4",
        "He3NLscoLHmv"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
